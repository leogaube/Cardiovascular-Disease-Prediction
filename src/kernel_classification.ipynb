{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Linear Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "sns.set_style(\"ticks\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classifying Cardio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         age  weight  cardio\nid                          \n0      18393    62.0       0\n1      20228    85.0       1\n2      18857    64.0       1\n3      17623    82.0       1\n4      17474    56.0       0\n...      ...     ...     ...\n99993  19240    76.0       0\n99995  22601   126.0       1\n99996  19066   105.0       1\n99998  22431    72.0       1\n99999  20540    72.0       0\n\n[70000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../resources/cardio_train.csv', sep=';', index_col='id')\n",
    "temp_df = pd.concat([data.age, data.weight, data.cardio], axis=1, join='inner')\n",
    "\n",
    "print(temp_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to feed the data to an algorithm, we have to convert the string 'type' to a numerical label ($\\{-1, +1\\}$ in this case).\n",
    "Create a new column 'label' which contains the value 1 if the type is 'sand' and -1 otherwise."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "patient_has_cardio = 1\n",
    "temp_df[\"label\"] = temp_df.apply(lambda row: 1 if (row.cardio == patient_has_cardio) else -1, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exploring the data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#sns.lmplot(x='weight', y='age', hue='cardio', data=df, fit_reg=False)\n",
    "# sns.lmplot(x='age', y='gender', hue='cardio', data=data, fit_reg=False).set(title='Age / Gender')\n",
    "# sns.lmplot(x='age', y='weight', hue='cardio', data=data, fit_reg=False).set(title='Age / Weight')\n",
    "# sns.lmplot(x='age', y='height', hue='cardio', data=data, fit_reg=False).set(title='Age / Height')\n",
    "# sns.lmplot(x='age', y='cholesterol', hue='cardio', data=data, fit_reg=False).set(title='Age / Cholesterol')\n",
    "# sns.lmplot(x='age', y='gluc', hue='cardio', data=data, fit_reg=False).set(title='Age / Glucose')\n",
    "# sns.lmplot(x='age', y='alco', hue='cardio', data=data, fit_reg=False).set(title='Age / Alcohol')\n",
    "# sns.lmplot(x='age', y='active', hue='cardio', data=data, fit_reg=False).set(title='Age / Active')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Result\n",
    "> The data is a mess and at the first look not linear separable. So a simple linear classification is not possible.\n",
    ">\n",
    "> A linear regression does not make sense with the result being a binary \"class\".\n",
    "\n",
    "### Kernel / Feature function\n",
    "\n",
    "Proceed by using introducing another dimension to make the data linear separable. This is done by using a feature function or kernel.\n",
    "\n",
    "linar: $h(x) = w^T*x$ or nonlinar: $h(x) = w^T*\\Phi(x)$\n",
    "\n",
    "Feature Function $\\Phi(x)$  based on Age = $A$ and Weight = $W$\n",
    "\n",
    "$x = [A, W] ∈ R^2$\n",
    "\n",
    "$ \\Phi(x_2) = [1, A, W, A^2, W^2, AW] ∈ R^6$ - optional with ($\\sqrt{2}$ for ease of calculation)\n",
    "\n",
    "\n",
    " With\n",
    " $ K(x, z) = \\Phi(x)^T\\Phi(z) = (x^T*z+1)^d$ with degree $d = 2$ for a two-dimensional input $x ∈ R^2$.\n",
    "\n",
    " $h(x) = w^T * \\Phi(x_i)= w^T*K(x,z) = w^T * (x^T*z+1)^d $\n",
    "\n",
    "$ min J(w) = \\frac{1}{m} \\sum_{i=1}^{m} l(h(x_i), y_i) + \\Omega(w)$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Kernel Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Datensatz teilen\n",
    "in validation, train und test\n",
    "\n",
    "### LOAD DATA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------------------------\nIMPORTING DATA\n------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*30); print(\"IMPORTING DATA\");print('-'*30)\n",
    "# limit dataset to 5000 instances for testing purposes (memory issues)\n",
    "df = pd.read_csv('../resources/cardio_train.csv', sep=';', index_col='id')[:5000] "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "# Min/Max Scaling on I=[0,1]: x_scaled = (x - min(x)) / (max(x) - min(x))\n",
    "df['age_scaled'] = ((df['age'])-min(df['age']))/(max(df['age'])-min(df['age']))\n",
    "df['height_scaled'] = ((df['height'])-min(df['height']))/(max(df['height'])-min(df['height']))\n",
    "df['weight_scaled'] = ((df['weight'])-min(df['weight']))/(max(df['weight'])-min(df['weight']))\n",
    "# Standardization: x_standardized = (x - µ) / sigma\n",
    "df['age_standardized'] = (df['age']-statistics.mean(df['age'])) / statistics.stdev(df['age'])\n",
    "df['height_standardized'] = (df['height']-statistics.mean(df['height'])) / statistics.stdev(df['height'])\n",
    "df['weight_standardized'] = (df['weight']-statistics.mean(df['weight'])) / statistics.stdev(df['weight'])\n",
    "\n",
    "df['bmi'] = (df['weight'] / ((df['height'] / 100) ** 2)).round(decimals=2)\n",
    "df['bmi_high'] = (df['bmi'] >= 30).astype(int)\n",
    "\n",
    "# eliminate corrupted Data\n",
    "df['ap_lo_fixed'] = [df['ap_lo'] if 50 < x < 150 else -1 for x in df['ap_lo']]\n",
    "df['ap_hi_fixed'] = [df['ap_hi'] if 100 < x < 190 else -1 for x in df['ap_hi']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "source": [
    "## Train / Validation / Test\n",
    "\n",
    "We'll first split our data into a Train set (70%) and Test set (30%).  \n",
    "The training set will be further processed using 10-fold-cross-validation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, train_proportion=0.7, shuffle=False):\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(data.shape[0])\n",
    "    else:\n",
    "        indices = np.arange(data.shape[0])\n",
    "\n",
    "    split_index = int(train_proportion * data.shape[0])\n",
    "    training_idx = indices[:split_index]\n",
    "    test_idx = indices[split_index:]\n",
    "\n",
    "    return data[training_idx, :], data[test_idx, :]\n",
    "\n",
    "\n",
    "def cross_val(data, k=10):\n",
    "    assert k >= 2\n",
    "    datasets = []\n",
    "\n",
    "    if data.shape[0] % k != 0:\n",
    "        print(\"warning: this dataset contains {} entries and cannot be euqally divided into {} chunks for cross-validation.\".format(data.shape[0], k))\n",
    "        print(\"Prutruding rows will be dropped.\")\n",
    "        data = data[ : (data.shape[0] // k) * k]\n",
    "\n",
    "    for i in range(k):\n",
    "        data_chunks = np.split(data, k)\n",
    "\n",
    "        val_data = data_chunks.pop(i)\n",
    "        train_data = np.concatenate(data_chunks)\n",
    "        datasets.append((train_data, val_data))\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio_data = df.to_numpy()\n",
    "train_data, test_data = train_test_split(cardio_data, shuffle=False)\n",
    "datasets = cross_val(train_data, k=10)\n",
    "\n",
    "#for train_set, val_set in datasets:\n",
    "\n",
    "# only use a single dataset for now\n",
    "train_set, val_set = datasets[0]\n",
    "X, y = np.hsplit(train_set, [11])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement the regularized kernlized logistic regression objective, give by\n",
    "\n",
    "$\n",
    "J(\\alpha) = \\frac{1}{m}\\sum_{i=1}^m  \\log \\big(1 + \\exp\\big(-y_i \\cdot \\sum_{j=1}^{m} \\alpha_j k(x_j,x_i)\\big) \\big) + \\lambda \\alpha^{\\intercal}K\\alpha\n",
    "$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def sqdist(X, Z):\n",
    "    p1 = np.sum(X**2, axis=1)[:, np.newaxis]\n",
    "    p2 = np.sum(Z**2, axis=1)\n",
    "    p3 = -2 * np.dot(X, Z.T)\n",
    "    return p1+p2+p3\n",
    "\n",
    "def sq_exp(X, Z, sigma):\n",
    "    return np.exp(-sqdist(X, Z)/(2*sigma**2) )\n",
    "\n",
    "\n",
    "def J(α, X, y, sigma, lam):\n",
    "    K = sq_exp(X, X, sigma)\n",
    "    m = X.shape[0]\n",
    "    total_loss = 0\n",
    "    regularization = lam * np.dot(np.dot(np.transpose(α), K), α)\n",
    "\n",
    "    for i in range(m):\n",
    "        prediction = 0\n",
    "        for j in range(m):\n",
    "            prediction += α[j]*K[i][j]\n",
    "        logistic_loss = np.log(1 + np.exp(-y[i] * prediction))\n",
    "        total_loss += logistic_loss\n",
    "\n",
    "    mean_loss = total_loss / m  + regularization\n",
    "    return mean_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement the gradient of the regularized kernlized logistic regression objective."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def dJ(α, X, y, sigma, lam):\n",
    "    K = sq_exp(X, X, sigma)\n",
    "    m = X.shape[0]\n",
    "    gradient = 0\n",
    "    regularization = 2*lam * np.dot( K, α)\n",
    "\n",
    "    for i in range(m):\n",
    "        prediction = 0\n",
    "        for j in range(m):\n",
    "            prediction += α[j]*K[i][j]\n",
    "\n",
    "        numerator = -y[i] * K[i]\n",
    "        denominator = 1 + np.exp(y[i] * prediction)\n",
    "        gradient += numerator / denominator\n",
    "\n",
    "    mean_gradient = gradient / m + regularization\n",
    "    return mean_gradient\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def plot_fit(h=None, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    s1 = ax.scatter(X[y>=0,0], X[y>=0,1], marker='.', color='gray')\n",
    "    s2 = ax.scatter(X[y<=0,0], X[y<=0,1], marker='.', color='orange')\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    plt.xlabel(\"Ip\")\n",
    "    plt.ylabel(\"Vp/Vs\")\n",
    "    plt.legend([s1,s2], ['sand', 'shale'])\n",
    "    if h:\n",
    "        grid =150\n",
    "        xx,yy = np.meshgrid(np.linspace(xlim[0], xlim[1], grid), np.linspace(ylim[0], ylim[1], grid))\n",
    "        XY = np.array([np.ravel(xx), np.ravel(yy)]).T\n",
    "        P = h(XY).reshape(grid, grid)\n",
    "        cn = ax.contour(xx, yy, P, colors='k',levels=10)\n",
    "        ax.clabel(cn, inline=1, fontsize=10)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "def kernel_lr(X, y, sigma, lam):\n",
    "    # implementation of kernel ridge regression using the scipy optimizer gradient descent\n",
    "    α = np.zeros(X.shape[0],)\n",
    "    α = minimize(J, α, args=(X, y, sigma, lam), jac=dJ, method='CG').x\n",
    "    h = lambda Z: np.dot(α, sq_exp(X, Z, sigma))\n",
    "    return h\n",
    "\n",
    "plot_fit(kernel_lr(X, y, sigma=0.5, lam=0.1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sigmas=[0.1, 1, 3]\n",
    "lambdas=[1e-10, 0.1, 1]\n",
    "\n",
    "fig, axs = plt.subplots(len(sigmas), len(lambdas), figsize=(15,15))\n",
    "for i, sigma in enumerate(sigmas):\n",
    "    for j, lam in enumerate(lambdas):\n",
    "        plot_fit(kernel_lr(X, y, sigma, lam), ax=axs[i,j])\n",
    "        axs[i,j].set_title(f'$\\sigma={sigma}$\\t$\\lambda={lam}$')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "name": "python391jvsc74a57bd0ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}